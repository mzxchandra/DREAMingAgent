2025-12-11 03:40:57,448 - __main__ - INFO - Starting Scaled Metric A (100 TFs) - Agentic Workflow
2025-12-11 03:40:57,448 - __main__ - INFO - Selecting top 100 TFs...
2025-12-11 03:40:57.449 | INFO     | src.utils.parsers:parse_tf_gene_network:111 - Detected network columns: {'tf_id': 0, 'tf_name': 1, 'gene_id': 3, 'gene_name': 4, 'effect': 5, 'evidence': 6}
2025-12-11 03:40:57.534 | INFO     | src.utils.parsers:parse_tf_gene_network:163 - Loaded RegulonDB network: 3103 nodes, 7323 edges
2025-12-11 03:40:57.699 | INFO     | src.utils.parsers:parse_m3d_expression:475 - Loaded M3D expression matrix: 4297 genes x 466 experiments
2025-12-11 03:40:57.702 | INFO     | src.utils.parsers:parse_gene_product_mapping:279 - Detected gene product columns: {'gene_id': 0, 'gene_name': 1, 'synonyms': 5, 'other_dbs': 6}
2025-12-11 03:40:57.714 | INFO     | src.utils.parsers:parse_gene_product_mapping:321 - Loaded gene mapping: 12903 names -> 4650 b-numbers
2025-12-11 03:40:57,716 - __main__ - INFO - Found 100 valid TFs. Returning top 100.
2025-12-11 03:40:57,716 - evaluation.metrics.base_metric - INFO - Starting execution of MetricASabotage...
2025-12-11 03:40:57,716 - evaluation.metrics.base_metric - INFO - [MetricASabotage] Preparing data...
2025-12-11 03:40:57,716 - evaluation.metrics.metric_a_sabotage - INFO - Preparing sabotage data from Real Network...
2025-12-11 03:40:57,899 - evaluation.metrics.metric_a_sabotage - INFO - Loaded real network with 7323 edges.
2025-12-11 03:40:57.900 | INFO     | src.utils.parsers:parse_gene_product_mapping:279 - Detected gene product columns: {'gene_id': 0, 'gene_name': 1, 'synonyms': 5, 'other_dbs': 6}
2025-12-11 03:40:57.912 | INFO     | src.utils.parsers:parse_gene_product_mapping:321 - Loaded gene mapping: 12903 names -> 4650 b-numbers
2025-12-11 03:40:58,001 - evaluation.metrics.metric_a_sabotage - INFO - Sabotage Summary for ['nhar', 'caif', 'arac', 'sgrr', 'leuo', 'cra', 'mraz', 'pdhr', 'dksa', 'cdar', 'rpsb', 'yafc', 'xynr', 'mata', 'rclr', 'beti', 'pdel', 'prpr', 'cynr', 'laci', 'mhpr', 'frmr', 'phob', 'nrdr', 'bola', 'decr', 'acrr', 'cuer', 'alls', 'allr', 'fimz', 'appy', 'envy', 'cusr', 'citr', 'dpia', 'nagc', 'fur', 'kdpe', 'mngr', 'mode', 'cecr', 'mntr', 'deor', 'rcda', 'lrp', 'rpsa', 'torr', 'rutr', 'puta', 'csgd', 'comr', 'phop', 'blur', 'fadr', 'dhar', 'narl', 'cysb', 'ycit', 'puur', 'pspf', 'ycjw', 'tyrr', 'pgrr', 'fnr', 'racr', 'ydat', 'fear', 'paax', 'ydci', 'sutr', 'hicb', 'mcbr', 'ydeo', 'hipb', 'lsrr', 'ptrr', 'marr', 'mara', 'rspr', 'relb', 'dica', 'dicf', 'mlc', 'rsta', 'uidr', 'mali', 'slya', 'nemr', 'purr', 'punr', 'ydip', 'rplt', 'chbr', 'nimr', 'kdgr', 'yebk', 'uvry', 'sdia', 'fliz']:
2025-12-11 03:40:58,002 - evaluation.metrics.metric_a_sabotage - INFO -   Injected 50 False Positives: ['cynr→hpt', 'rutr→psd', 'fadr→yhaj', 'citr→hflx', 'fimz→hycd', 'cusr→pdeh', 'leuo→leuv', 'narl→spfp', 'cysb→rzpr', 'mcbr→fur', 'mlc→pabb', 'yebk→aroe', 'fliz→glnb', 'racr→yedl', 'rclr→ulae', 'pdhr→btue', 'dhar→cas2', 'phob→fumd', 'envy→ansp', 'deor→alsb', 'fur→yafo', 'rpsa→hlye', 'dicf→exbd', 'racr→rbfa', 'beti→yeha', 'rcda→tord', 'sgrr→uvrb', 'mhpr→arnb', 'ycjw→glpe', 'nhar→yhft', 'uvry→glpd', 'cysb→narh', 'pdel→frlr', 'rpsa→ilvc', 'mode→dicc', 'punr→oxys', 'yebk→hcar', 'comr→rbfa', 'mode→nrfd', 'dicf→thiq', 'kdgr→tort', 'acrr→beta', 'narl→ymda', 'ycit→alav', 'pgrr→ydcc', 'uidr→mlab', 'chbr→mgtl', 'envy→rplp', 'envy→serb', 'slya→yiho']
2025-12-11 03:40:58,002 - evaluation.metrics.metric_a_sabotage - INFO -   Deleted 50 True Edges: ['pdhr→mure', 'mcbr→ycif', 'slya→hlye', 'hipb→euta', 'cra→frua', 'fur→gspl', 'slya→sgca', 'pdel→flig', 'phob→rcdb', 'nhar→gltw', 'mata→flhc', 'mata→mata', 'nhar→alau', 'fnr→fnr', 'fur→lysp', 'arac→ygea', 'nhar→rrle', 'phob→phno', 'fur→ybix', 'fur→yihn', 'caif→fixa', 'rutr→gloa', 'dksa→rybb', 'fliz→gadb', 'rclr→rclb', 'phob→phnn', 'ydeo→hyae', 'narl→nark', 'nhar→rsd', 'frmr→frmr', 'cysb→hslj', 'cra→tmar', 'fur→succ', 'slya→cas1', 'ydeo→hyac', 'nagc→chiz', 'fnr→nuon', 'narl→fdhf', 'phob→hiuh', 'cra→seta', 'fnr→hype', 'fnr→nuoj', 'nhar→ileu', 'narl→ynff', 'fur→mnth', 'fur→dmsc', 'mara→pqic', 'lrp→oppf', 'slya→paai', 'fur→rnpb']
2025-12-11 03:40:58,010 - evaluation.metrics.base_metric - INFO - [MetricASabotage] Running evaluation...
2025-12-11 03:40:58,010 - evaluation.metrics.metric_a_sabotage - INFO - Running reconciliation on sabotaged network...
2025-12-11 03:40:58.010 | INFO     | src.workflow:run_reconciliation:141 - ============================================================
2025-12-11 03:40:58.010 | INFO     | src.workflow:run_reconciliation:142 - STARTING AGENTIC RECONCILIATION PIPELINE
2025-12-11 03:40:58.010 | INFO     | src.workflow:run_reconciliation:143 - ============================================================
2025-12-11 03:40:58.010 | INFO     | src.workflow:create_reconciliation_workflow:48 - Creating reconciliation workflow...
2025-12-11 03:40:58.011 | INFO     | src.workflow:create_reconciliation_workflow:99 - Workflow created successfully
2025-12-11 03:40:58.019 | INFO     | src.workflow:run_reconciliation:164 - Executing workflow...
2025-12-11 03:40:58.020 | INFO     | src.nodes.loader:loader_node:70 - === LOADER NODE: Ingesting data files ===
2025-12-11 03:40:58.020 | INFO     | src.nodes.loader:loader_node:89 - Loading gene name to b-number mapping...
2025-12-11 03:40:58.021 | INFO     | src.utils.parsers:parse_gene_product_mapping:279 - Detected gene product columns: {'gene_id': 0, 'gene_name': 1, 'synonyms': 5, 'other_dbs': 6}
2025-12-11 03:40:58.032 | INFO     | src.utils.parsers:parse_gene_product_mapping:321 - Loaded gene mapping: 12903 names -> 4650 b-numbers
2025-12-11 03:40:58.032 | INFO     | src.nodes.loader:loader_node:101 - Loading RegulonDB TF-Gene regulatory network...
2025-12-11 03:40:58.033 | INFO     | src.utils.parsers:parse_tf_gene_network:111 - Detected network columns: {'tf_id': 0, 'tf_name': 1, 'gene_id': 3, 'gene_name': 4, 'effect': 5, 'evidence': 6}
2025-12-11 03:40:58.053 | INFO     | src.utils.parsers:parse_tf_gene_network:163 - Loaded RegulonDB network: 3182 nodes, 7323 edges
2025-12-11 03:40:58.061 | INFO     | src.nodes.loader:loader_node:111 - Literature graph: 2855 nodes, 7320 edges
2025-12-11 03:40:58.061 | INFO     | src.nodes.loader:loader_node:122 - Loading M3D expression matrix...
2025-12-11 03:40:58.189 | INFO     | src.utils.parsers:parse_m3d_expression:475 - Loaded M3D expression matrix: 4297 genes x 466 experiments
2025-12-11 03:40:58.190 | INFO     | src.nodes.loader:loader_node:132 - Expression matrix: 4297 genes x 466 experiments
2025-12-11 03:40:58.190 | INFO     | src.nodes.loader:loader_node:146 - Loading M3D experimental metadata...
2025-12-11 03:40:58.195 | INFO     | src.utils.parsers:parse_m3d_metadata:509 - Loaded M3D metadata: 907 experiments with 2 attributes
2025-12-11 03:40:58.195 | INFO     | src.nodes.loader:loader_node:149 - Metadata: 907 experiments
2025-12-11 03:40:58.196 | INFO     | src.nodes.loader:loader_node:174 - Filtered TF queue to 100 targets: ['b0889', 'b1334', 'b0683', 'b0145', 'b0080', 'b1221', 'b0399', 'b1130', 'b1531', 'b0113', 'b0761', 'b1642', 'b0676', 'b0020', 'b1275', 'b1658', 'b1040', 'b0076', 'b1187', 'b1499', 'b1921', 'b0995', 'b0081', 'b0064', 'b1013', 'b0464', 'b0571', 'b0846', 'b1399', 'b1526', 'b1323', 'b1320', 'b0435', 'b0620', 'b1594', 'b0069', 'b1608', 'b0564', 'b0162', 'b1328', 'b0034', 'b1512', 'b0315', 'b0506', 'b0487', 'b0694', 'b0413', 'b1570', 'b1299', 'b1916', 'b1434', 'b1303', 'b1356', 'b1735', 'b0346', 'b0911', 'b0294', 'b1914', 'b1508', 'b0840', 'b1574', 'b1450', 'b0796', 'b0535', 'b0330', 'b1284', 'b0272', 'b0817', 'b0338', 'b1201', 'b1422', 'b0313', 'b1618', 'b0566', 'b1162', 'b0603', 'b0169', 'b0345', 'b1620', 'b1530', 'b1827', 'b0730', 'b1564', 'b0504', 'b1649', 'b1853', 'b0305', 'b1111', 'b1384', 'b1438', 'b1716', 'b0447', 'b1014', 'b1696', 'b1790', 'b0357', 'b1540', 'b1659', 'b0208', 'b1358']
2025-12-11 03:40:58.196 | INFO     | src.nodes.loader:loader_node:179 - Initialized TF queue with 100 transcription factors
2025-12-11 03:40:58.197 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 03:40:58.197 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 1: Processing batch of 5 TFs (95 remaining)
2025-12-11 03:40:58.197 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b0889', 'b1334', 'b0683', 'b0145', 'b0080']
2025-12-11 03:40:58.197 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 03:40:58.197 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 03:40:58.201 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 19 samples selected from 466 total
2025-12-11 03:40:58.365 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 1255 pairs for speed
2025-12-11 03:40:58.365 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 03:40:58.365 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0889 -> b0886
2025-12-11 03:40:58.369 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 03:41:01,678 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:02.286 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 03:41:04,586 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:04.587 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 03:41:06,671 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:06.672 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 03:41:08,182 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:08.184 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0889 -> b4014
2025-12-11 03:41:08.185 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 03:41:11,693 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:12.061 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 03:41:13,601 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:13.602 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 03:41:16,107 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:16.107 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 03:41:17,107 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:17.109 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0889 -> b1241
2025-12-11 03:41:17.110 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 03:41:19,208 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:19.603 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 03:41:21,348 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:21.350 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 03:41:23,180 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:23.180 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 03:41:24,820 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:24.822 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0889 -> b2697
2025-12-11 03:41:24.822 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 03:41:26,747 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:27.126 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 03:41:28,836 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:28.837 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 03:41:30,835 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:41:30.836 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 03:42:33,431 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:42:33.437 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0889 -> b2957
2025-12-11 03:42:33.438 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 03:42:35,783 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:42:36.489 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 03:42:38,360 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:42:38.361 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 03:42:40,288 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:42:40.289 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 03:42:41,851 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:42:41.852 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 03:42:41.852 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 03:42:41.853 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 03:42:41.865 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 19 samples
2025-12-11 03:42:41.870 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0889
2025-12-11 03:42:42.862 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0889: 1 high, 183 moderate significance hits
2025-12-11 03:42:42.864 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1334
2025-12-11 03:42:43.938 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1334: 3 high, 144 moderate significance hits
2025-12-11 03:42:43.938 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0683
2025-12-11 03:42:44.983 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0683: 0 high, 151 moderate significance hits
2025-12-11 03:42:44.984 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0145
2025-12-11 03:42:46.047 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0145: 4 high, 136 moderate significance hits
2025-12-11 03:42:46.047 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0080
2025-12-11 03:42:47.097 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0080: 2 high, 151 moderate significance hits
2025-12-11 03:42:47.097 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 03:42:47.098 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 03:42:47.098 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b0889: 367 lit targets, 467 stat targets, 503 total
2025-12-11 03:44:21.947 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 503 edges for TF b0889
2025-12-11 03:44:21.965 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 503 edges in 11 batches (Max 50/batch)
2025-12-11 03:44:21.965 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/11 (50 edges)
2025-12-11 03:46:24,288 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:46:24.294 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 03:46:24.294 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 03:46:24.296 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/11 (50 edges)
2025-12-11 03:47:53,885 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:47:53.887 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 2 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 03:47:53.887 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 03:47:53.888 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/11 (50 edges)
2025-12-11 03:49:31,014 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:49:31.018 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 3 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 03:49:31.018 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 03:49:31.019 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/11 (50 edges)
2025-12-11 03:51:21,030 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:51:21.033 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 4 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 03:51:21.033 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 03:51:21.034 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 5/11 (50 edges)
2025-12-11 03:52:43,318 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:52:43.321 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 5 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 03:52:43.321 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 03:52:43.321 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 6/11 (50 edges)
2025-12-11 03:54:15,456 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:54:15.461 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 6 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 03:54:15.461 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 03:54:15.461 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 7/11 (50 edges)
2025-12-11 03:55:33,022 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:55:33.026 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 7 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 03:55:33.026 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 03:55:33.027 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 8/11 (50 edges)
2025-12-11 03:56:44,419 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:56:44.424 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 9/11 (50 edges)
2025-12-11 03:58:39,721 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 03:58:39.723 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 9 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 03:58:39.723 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 03:58:39.723 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 10/11 (50 edges)
2025-12-11 04:00:08,611 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:00:08.615 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 10 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:00:08.615 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:00:08.616 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 11/11 (3 edges)
2025-12-11 04:00:28,057 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:00:28.063 | WARNING  | src.nodes.reviewer_agent:reviewer_agent_node:90 - LLM failed (4 validation errors for SubgraphReview
edge_decisions.358.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Weak literature combined...bableFalsePos criteria.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.365.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Weak literature combined...bleFalsePos definition.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.381.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Weak literature and a CL...bableFalsePos criteria.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.384.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Weak literature combined...bleFalsePos definition.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short), using rule-based fallback
2025-12-11 04:00:28.065 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b0889' using RULES method

Edges Reviewed: 503

Status Breakdown:
  - ConditionSilent: 268
  - ProbableFalsePos: 216
  - Validated: 19

TF-Level Notes:
Rule-based fallback used (LLM unavailable)

2025-12-11 04:00:28.067 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 04:00:28.067 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 2: Processing batch of 5 TFs (90 remaining)
2025-12-11 04:00:28.067 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1221', 'b0399', 'b1130', 'b1531', 'b0113']
2025-12-11 04:00:28.067 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 04:00:28.067 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 04:00:28.070 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 04:00:28.072 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 356 pairs for speed
2025-12-11 04:00:28.072 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 04:00:28.072 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1221 -> b4123
2025-12-11 04:00:28.073 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:01:27,917 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:28.516 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:01:30,918 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:30.919 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:01:32,601 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:32.601 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:01:34,231 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:34.232 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1221 -> b0886
2025-12-11 04:01:34.232 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:01:37,225 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:37.595 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:01:38,939 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:38.940 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:01:40,043 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:40.044 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:01:40,964 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:40.965 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1221 -> b1241
2025-12-11 04:01:40.966 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:01:44,960 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:45.329 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:01:47,624 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:47.625 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:01:50,251 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:50.252 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:01:51,750 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:51.751 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1221 -> b4139
2025-12-11 04:01:51.751 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:01:54,252 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:54.633 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:01:56,326 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:56.327 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:01:58,588 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:01:58.589 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:02:00,144 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:02:00.145 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1221 -> b0827
2025-12-11 04:02:00.145 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:02:03,268 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:02:03.635 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:02:05,242 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:02:05.242 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:02:07,079 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:02:07.080 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:02:08,170 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:02:08.172 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 04:02:08.172 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 04:02:08.173 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 04:02:08.175 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 04:02:08.183 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1221
2025-12-11 04:02:12.105 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1221: 1 high, 154 moderate significance hits
2025-12-11 04:02:12.105 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0399
2025-12-11 04:02:16.000 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0399: 8 high, 129 moderate significance hits
2025-12-11 04:02:16.001 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1130
2025-12-11 04:02:19.769 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1130: 4 high, 125 moderate significance hits
2025-12-11 04:02:19.770 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1531
2025-12-11 04:02:23.472 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1531: 3 high, 154 moderate significance hits
2025-12-11 04:02:23.472 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0113
2025-12-11 04:02:27.208 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0113: 1 high, 169 moderate significance hits
2025-12-11 04:02:27.209 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 04:02:27.209 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 04:02:27.209 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1221: 124 lit targets, 270 stat targets, 272 total
2025-12-11 04:03:19.298 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 272 edges for TF b1221
2025-12-11 04:03:19.302 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 272 edges in 6 batches (Max 50/batch)
2025-12-11 04:03:19.303 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/6 (50 edges)
2025-12-11 04:04:34,437 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:04:34.442 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/6 (50 edges)
2025-12-11 04:06:23,286 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:06:23.294 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 2 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:06:23.294 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:06:23.295 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/6 (50 edges)
2025-12-11 04:07:48,251 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:07:48.254 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 3 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:07:48.254 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:07:48.254 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/6 (50 edges)
2025-12-11 04:09:13,986 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:09:13.990 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 4 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:09:13.990 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:09:13.991 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 5/6 (50 edges)
2025-12-11 04:11:28,646 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:11:28.651 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 5 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:11:28.652 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:11:28.652 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 6/6 (22 edges)
2025-12-11 04:13:16,367 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:16.372 | WARNING  | src.nodes.reviewer_agent:reviewer_agent_node:90 - LLM failed (12 validation errors for SubgraphReview
edge_decisions.14.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absent literature and a ...ikely a false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.32.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absent literature and a ...dge is likely spurious.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.33.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature and a CLR ...ficient for validation.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.35.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature and a CLR ...ficient for confidence.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.36.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Weak literature (negativ...‑positive definition.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.37.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature and a CLR ...dge is likely spurious.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.39.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature and a CLR ...ikely a false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.42.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature and a CLR ...dge is likely spurious.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.44.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature and a CLR ...ficient for validation.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.45.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Weak literature (negativ...se‑positive criteria.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.46.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature and a CLR ...dge is likely spurious.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.48.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Weak literature (negativ...robable false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short), using rule-based fallback
2025-12-11 04:13:16.374 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1221' using RULES method

Edges Reviewed: 272

Status Breakdown:
  - ConditionSilent: 217
  - NovelHypothesis: 1
  - ProbableFalsePos: 51
  - Validated: 3

TF-Level Notes:
Rule-based fallback used (LLM unavailable)

2025-12-11 04:13:16.375 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 04:13:16.375 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 3: Processing batch of 5 TFs (85 remaining)
2025-12-11 04:13:16.375 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b0761', 'b1642', 'b0676', 'b0020', 'b1275']
2025-12-11 04:13:16.375 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 04:13:16.376 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 04:13:16.378 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 04:13:16.387 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 208 pairs for speed
2025-12-11 04:13:16.388 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 04:13:16.388 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0761 -> b0764
2025-12-11 04:13:16.389 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:13:18,900 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:19.392 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:13:21,483 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:21.484 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:13:24,250 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:24.251 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:13:25,631 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:25.635 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0761 -> b0765
2025-12-11 04:13:25.637 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:13:27,711 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:29.364 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:13:30,891 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:30.895 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:13:32,890 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:32.891 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:13:33,916 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:33.918 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0761 -> b4382
2025-12-11 04:13:33.918 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:13:38,666 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:39.854 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:13:42,043 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:42.044 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:13:43,468 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:43.468 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:13:44,525 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:44.526 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0761 -> b4383
2025-12-11 04:13:44.527 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:13:46,918 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:47.315 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:13:50,246 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:50.247 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:13:52,742 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:52.747 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:13:53,930 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:53.931 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0761 -> b4381
2025-12-11 04:13:53.931 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:13:55,659 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:55.999 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:13:58,446 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:13:58.447 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:14:01,013 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:14:01.014 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:14:02,339 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:14:02.340 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 04:14:02.340 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 04:14:02.341 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 04:14:02.343 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 04:14:02.349 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0761
2025-12-11 04:14:06.139 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0761: 3 high, 168 moderate significance hits
2025-12-11 04:14:06.140 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1642
2025-12-11 04:14:09.962 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1642: 5 high, 171 moderate significance hits
2025-12-11 04:14:09.962 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0676
2025-12-11 04:14:13.755 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0676: 1 high, 183 moderate significance hits
2025-12-11 04:14:13.756 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0020
2025-12-11 04:14:17.660 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0020: 3 high, 142 moderate significance hits
2025-12-11 04:14:17.660 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1275
2025-12-11 04:14:21.380 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1275: 5 high, 166 moderate significance hits
2025-12-11 04:14:21.380 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 04:14:21.381 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 04:14:21.381 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b0761: 48 lit targets, 213 stat targets, 213 total
2025-12-11 04:15:01.374 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 213 edges for TF b0761
2025-12-11 04:15:01.378 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 213 edges in 5 batches (Max 50/batch)
2025-12-11 04:15:01.378 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/5 (50 edges)
2025-12-11 04:17:10,228 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:17:10.230 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:17:10.231 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:17:10.231 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/5 (50 edges)
2025-12-11 04:19:06,880 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:19:06.884 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/5 (50 edges)
2025-12-11 04:20:24,048 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:20:24.051 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/5 (50 edges)
2025-12-11 04:21:42,202 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:21:42.203 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 4 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:21:42.204 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:21:42.204 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 5/5 (13 edges)
2025-12-11 04:22:34,433 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:34.438 | WARNING  | src.nodes.reviewer_agent:reviewer_agent_node:90 - LLM failed (23 validation errors for SubgraphReview
edge_decisions.73.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature exists for...ficient for validation.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.84.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature exists; th...ong‑data requirement.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.85.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No experimental support ...ficient for validation.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.88.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absence of any reported ...s the edge unsupported.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.89.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature evidence; ...ficient for validation.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.94.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No published interaction...ficient for validation.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.95.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absence of literature co...a for a validated edge.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.96.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature evidence; ...ficient for validation.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.98.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature exists; th... validated interaction.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.99.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absence of any experimen...s the edge unsupported.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.114.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absent literature; CLR 2...lsePos and is not kept.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.116.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature; CLR 2.09 ...eFalsePos and excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.122.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature; CLR 2.05 ...s and should be pruned.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.124.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature; CLR 2.28 ...eFalsePos and excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.125.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absent literature; CLR 2...alsePos and is removed.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.128.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature; CLR 3.28 ...eFalsePos and excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.130.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature; CLR 2.27 ...eFalsePos and excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.132.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absent literature; CLR 2...leFalsePos and removed.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.136.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature; CLR 3.17 ...eFalsePos and excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.140.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absent literature; CLR 2...eFalsePos and excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.144.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absent literature; CLR 2...and should be excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.147.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absent literature; CLR 2...eFalsePos and excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.149.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature evidence; ...eFalsePos and excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short), using rule-based fallback
2025-12-11 04:22:34.440 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b0761' using RULES method

Edges Reviewed: 213

Status Breakdown:
  - ConditionSilent: 200
  - NovelHypothesis: 3
  - ProbableFalsePos: 7
  - Validated: 3

TF-Level Notes:
Rule-based fallback used (LLM unavailable)

2025-12-11 04:22:34.442 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 04:22:34.442 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 4: Processing batch of 5 TFs (80 remaining)
2025-12-11 04:22:34.442 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1658', 'b1040', 'b0076', 'b1187', 'b1499']
2025-12-11 04:22:34.442 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 04:22:34.442 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 04:22:34.444 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 04:22:34.446 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 131 pairs for speed
2025-12-11 04:22:34.446 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 04:22:34.446 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1658 -> b0032
2025-12-11 04:22:34.447 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:22:36,445 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:37.947 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:22:39,445 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:39.446 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:22:41,288 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:41.289 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:22:42,317 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:42.319 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1658 -> b0033
2025-12-11 04:22:42.319 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:22:44,725 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:45.088 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:22:47,326 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:47.326 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:22:49,758 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:49.758 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:22:51,320 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:51.322 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1658 -> b2313
2025-12-11 04:22:51.322 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:22:53,576 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:53.931 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:22:55,848 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:55.849 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:22:57,913 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:57.914 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:22:58,999 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:22:59.000 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1658 -> b2904
2025-12-11 04:22:59.000 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:23:01,782 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:23:02.203 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:23:03,423 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:23:03.425 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:23:04,992 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:23:04.992 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:23:06,427 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:23:06.428 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1658 -> b2553
2025-12-11 04:23:06.429 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:23:08,439 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:23:08.877 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:23:10,573 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:23:10.575 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:23:12,782 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:23:12.783 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:23:14,056 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:23:14.057 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 04:23:14.057 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 04:23:14.057 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 04:23:14.058 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 04:23:14.064 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1658
2025-12-11 04:23:18.025 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1658: 4 high, 174 moderate significance hits
2025-12-11 04:23:18.026 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1040
2025-12-11 04:23:22.253 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1040: 5 high, 150 moderate significance hits
2025-12-11 04:23:22.253 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0076
2025-12-11 04:23:26.273 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0076: 7 high, 156 moderate significance hits
2025-12-11 04:23:26.274 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1187
2025-12-11 04:23:30.105 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1187: 4 high, 155 moderate significance hits
2025-12-11 04:23:30.106 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1499
2025-12-11 04:23:34.108 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1499: 19 high, 159 moderate significance hits
2025-12-11 04:23:34.109 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 04:23:34.109 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 04:23:34.109 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1658: 32 lit targets, 196 stat targets, 197 total
2025-12-11 04:24:09.892 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 197 edges for TF b1658
2025-12-11 04:24:09.895 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 197 edges in 4 batches (Max 50/batch)
2025-12-11 04:24:09.895 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 04:26:30,253 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:26:30.258 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:26:30.258 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:26:30.259 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 04:27:42,444 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:27:42.446 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 04:29:15,422 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:29:15.425 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 3 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:29:15.426 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:29:15.427 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (47 edges)
2025-12-11 04:31:22,296 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:22.300 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1658' using LLM method

Edges Reviewed: 197

Status Breakdown:
  - ConditionSilent: 96
  - NovelHypothesis: 4
  - ProbableFalsePos: 89
  - Uncertain: 2
  - Validated: 6

TF-Level Notes:
Batch 2: The TF b1658 shows limited literature support, with only a handful of strong or weak citations. Most predicted targets lack any published evidence, and none achieve the CLR >4 threshold required for strong data validation. Consequently, the majority of edges are classified as probable false positives, with a few ConditionSilent edges retained due to strong literature despite weak statistical support. No edge meets the criteria for validated regulation. | Batch 4: The transcription factor b1658 shows no expression data in the current dataset, limiting the ability to assess condition‑specific regulation. Most predicted edges lack literature support and exhibit only moderate statistical signals, leading to a predominance of probable false‑positive classifications. Two edges (b1658→b1729 and b1658→b1686) display strong CLR scores (>4.0) without prior literature, representing novel hypotheses that merit targeted experimental validation. Three edges (b1658→b1062, b1658→b2500, b1658→b2313) have confirmed literature but weak statistical support under the present conditions, fitting the ConditionSilent category.

2025-12-11 04:31:22.302 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 04:31:22.302 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 5: Processing batch of 5 TFs (75 remaining)
2025-12-11 04:31:22.302 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1921', 'b0995', 'b0081', 'b0064', 'b1013']
2025-12-11 04:31:22.302 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 04:31:22.303 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 04:31:22.308 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 04:31:22.311 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 95 pairs for speed
2025-12-11 04:31:22.311 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 04:31:22.312 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1921 -> b1891
2025-12-11 04:31:22.313 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:31:24,755 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:25.260 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:31:27,208 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:27.210 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:31:29,218 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:29.219 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:31:30,793 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:30.795 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1921 -> b1892
2025-12-11 04:31:30.796 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:31:33,147 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:33.545 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:31:35,300 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:35.301 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:31:37,761 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:37.762 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:31:39,298 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:39.300 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1921 -> b4376
2025-12-11 04:31:39.300 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:31:41,290 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:41.657 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:31:43,182 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:43.183 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:31:45,332 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:45.334 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:31:46,616 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:46.618 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1921 -> b3510
2025-12-11 04:31:46.619 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:31:49,807 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:50.177 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:31:52,195 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:52.197 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:31:55,371 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:55.372 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:31:56,907 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:56.909 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1921 -> b3509
2025-12-11 04:31:56.910 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:31:58,849 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:31:59.220 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:32:02,028 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:32:02.030 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:32:03,872 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:32:03.873 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:32:05,403 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:32:05.404 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 04:32:05.405 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 04:32:05.405 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 04:32:05.406 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 04:32:05.413 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1921
2025-12-11 04:32:09.237 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1921: 52 high, 70 moderate significance hits
2025-12-11 04:32:09.238 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0995
2025-12-11 04:32:13.235 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0995: 0 high, 150 moderate significance hits
2025-12-11 04:32:13.235 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0081
2025-12-11 04:32:17.190 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0081: 6 high, 148 moderate significance hits
2025-12-11 04:32:17.191 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0064
2025-12-11 04:32:21.056 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0064: 7 high, 121 moderate significance hits
2025-12-11 04:32:21.056 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1013
2025-12-11 04:32:25.034 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1013: 0 high, 132 moderate significance hits
2025-12-11 04:32:25.035 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 04:32:25.035 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 04:32:25.036 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1921: 22 lit targets, 89 stat targets, 90 total
2025-12-11 04:32:46.189 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 90 edges for TF b1921
2025-12-11 04:32:46.192 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 90 edges in 2 batches (Max 50/batch)
2025-12-11 04:32:46.192 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/2 (50 edges)
2025-12-11 04:34:56,725 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:34:56.729 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:34:56.729 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:34:56.730 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/2 (40 edges)
2025-12-11 04:37:28,476 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:28.481 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1921' using LLM method

Edges Reviewed: 90

Status Breakdown:
  - ConditionSilent: 31
  - NovelHypothesis: 49
  - ProbableFalsePos: 8
  - Validated: 2

TF-Level Notes:
Batch 2: The transcription factor b1921 has unknown expression status; no quantitative expression data are available. Consequently, condition matching could not be evaluated for any downstream target. The majority of edges lack literature support, but many display strong CLR scores, suggesting novel regulatory relationships that merit experimental follow‑up. Edges with strong literature but weak or absent statistical support are retained as ConditionSilent, reflecting possible context‑specific regulation not captured in the current dataset.

2025-12-11 04:37:28.483 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 04:37:28.483 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 6: Processing batch of 5 TFs (70 remaining)
2025-12-11 04:37:28.483 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b0464', 'b0571', 'b0846', 'b1399', 'b1526']
2025-12-11 04:37:28.483 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 04:37:28.484 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 04:37:28.485 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 04:37:28.486 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 73 pairs for speed
2025-12-11 04:37:28.486 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 04:37:28.487 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0464 -> b1891
2025-12-11 04:37:28.488 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:37:31,825 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:32.580 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:37:34,415 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:34.419 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:37:35,746 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:35.748 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:37:37,077 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:37.081 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0464 -> b1892
2025-12-11 04:37:37.082 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:37:39,328 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:39.721 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:37:41,379 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:41.383 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:37:43,322 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:43.325 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:37:45,062 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:45.067 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0464 -> b4063
2025-12-11 04:37:45.068 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:37:47,320 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:47.709 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:37:49,569 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:49.570 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:37:51,309 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:51.312 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:37:52,641 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:52.641 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0464 -> b4062
2025-12-11 04:37:52.642 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:37:54,792 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:55.211 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:37:57,155 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:57.159 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:37:59,094 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:37:59.095 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:38:00,631 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:38:00.636 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0464 -> b1531
2025-12-11 04:38:00.637 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:38:02,675 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:38:03.090 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:38:05,134 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:38:05.137 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:38:07,386 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:38:07.389 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:38:08,420 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:38:08.424 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 04:38:08.424 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 04:38:08.425 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 04:38:08.426 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 04:38:08.430 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0464
2025-12-11 04:38:12.202 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0464: 2 high, 156 moderate significance hits
2025-12-11 04:38:12.202 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0571
2025-12-11 04:38:15.949 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0571: 4 high, 140 moderate significance hits
2025-12-11 04:38:15.950 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0846
2025-12-11 04:38:19.719 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0846: 4 high, 155 moderate significance hits
2025-12-11 04:38:19.719 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1399
2025-12-11 04:38:23.344 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1399: 2 high, 157 moderate significance hits
2025-12-11 04:38:23.344 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1526
2025-12-11 04:38:26.971 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1526: 12 high, 203 moderate significance hits
2025-12-11 04:38:26.972 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 04:38:26.972 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 04:38:26.972 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b0464: 16 lit targets, 168 stat targets, 170 total
2025-12-11 04:39:05.554 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 170 edges for TF b0464
2025-12-11 04:39:05.558 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 170 edges in 4 batches (Max 50/batch)
2025-12-11 04:39:05.559 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 04:41:07,920 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:41:07.924 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:41:07.924 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:41:07.924 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 04:44:59,928 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:44:59.930 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 04:47:39,778 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:47:39.782 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (20 edges)
2025-12-11 04:48:17,464 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:48:17.469 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b0464' using LLM method

Edges Reviewed: 170

Status Breakdown:
  - ConditionSilent: 57
  - NovelHypothesis: 1
  - ProbableFalsePos: 17
  - Reviewed: 50
  - Uncertain: 45

TF-Level Notes:
Batch 2: The transcription factor b0464 shows no documented expression profile in the current dataset, and none of the 50 candidate targets have documented regulatory evidence under the examined conditions. Only a handful of edges (b0464→b1600, b0464→b1530, b0464→b4062) are supported by strong literature but lack statistical corroboration, placing them in a condition‑silent category. One edge (b0464→b0434) meets the NovelHypothesis criteria due to a strong CLR (>4) despite no literature. The majority of predicted edges have moderate to weak statistical support and no literature, leading to their classification as uncertain or low‑confidence predictions. Further experimental validation, especially under condition‑specific assays, is required to confirm any of these regulatory links. | Batch 3: TF b0464 (acrr) has unknown expression status in the current dataset, limiting condition‑specific interpretation. Only a few edges (b0464->b0463, b0464->b0462, b0464->b4439, b0464->b4777, b0464->b0464) have literature support; among these, only the b0464->b0463 interaction meets both strong literature and strong statistical evidence and is thus validated. All other edges lack literature and/or have only moderate statistical signals, leading to their classification as probable false positives. Future experiments should focus on the validated edge and explore condition‑specific regulation for the condition‑silent candidates. | Batch 4: TF b0464 has unknown expression status; no mean expression or percentile data are available. Consequently, contextual validation of its regulatory edges is limited. Several edges (b1599, b1297, b4063, b1531) are supported by strong literature but lack statistical signal in the current dataset, suggesting condition‑specific activity. All other edges lack literature support and exhibit only weak statistical associations, indicating they are likely false positives.

2025-12-11 04:48:17.471 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 04:48:17.471 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 7: Processing batch of 5 TFs (65 remaining)
2025-12-11 04:48:17.471 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1323', 'b1320', 'b0435', 'b0620', 'b1594']
2025-12-11 04:48:17.471 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 04:48:17.472 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 04:48:17.477 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 04:48:17.488 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 57 pairs for speed
2025-12-11 04:48:17.488 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 04:48:17.488 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1323 -> b2601
2025-12-11 04:48:17.489 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:48:56,378 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:48:56.905 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:48:58,789 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:48:58.791 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:49:00,982 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:00.984 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:49:02,521 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:02.525 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1323 -> b0754
2025-12-11 04:49:02.526 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:49:04,363 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:04.811 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:49:06,511 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:06.514 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:49:08,354 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:08.356 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:49:09,897 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:09.901 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1323 -> b0388
2025-12-11 04:49:09.902 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:49:12,453 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:12.842 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:49:15,473 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:15.477 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:49:17,981 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:17.983 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:49:19,414 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:19.418 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1323 -> b0390
2025-12-11 04:49:19.419 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:49:21,051 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:21.428 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:49:23,463 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:23.466 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:49:25,456 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:25.458 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:49:26,889 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:26.894 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1323 -> b0112
2025-12-11 04:49:26.895 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:49:29,861 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:30.249 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:49:33,135 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:33.138 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:49:35,592 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:35.593 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:49:36,924 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:49:36.927 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 04:49:36.928 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 04:49:36.928 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 04:49:36.929 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 04:49:36.934 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1323
2025-12-11 04:49:40.646 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1323: 4 high, 152 moderate significance hits
2025-12-11 04:49:40.646 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1320
2025-12-11 04:49:44.296 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1320: 1 high, 185 moderate significance hits
2025-12-11 04:49:44.296 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0435
2025-12-11 04:49:47.971 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0435: 15 high, 189 moderate significance hits
2025-12-11 04:49:47.972 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0620
2025-12-11 04:49:51.721 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0620: 1 high, 158 moderate significance hits
2025-12-11 04:49:51.722 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1594
2025-12-11 04:49:55.454 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1594: 3 high, 156 moderate significance hits
2025-12-11 04:49:55.454 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 04:49:55.454 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 04:49:55.455 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1323: 12 lit targets, 163 stat targets, 164 total
2025-12-11 04:50:28.631 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 164 edges for TF b1323
2025-12-11 04:50:28.636 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 164 edges in 4 batches (Max 50/batch)
2025-12-11 04:50:28.636 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 04:52:03,157 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:52:03.160 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:52:03.161 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:52:03.162 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 04:53:09,824 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:53:09.827 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 04:55:31,031 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:55:31.035 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 3 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 04:55:31.036 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 04:55:31.037 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (14 edges)
2025-12-11 04:56:16,604 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:16.610 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1323' using LLM method

Edges Reviewed: 164

Status Breakdown:
  - ConditionSilent: 100
  - NovelHypothesis: 4
  - ProbableFalsePos: 46
  - Reviewed: 14

TF-Level Notes:
Batch 2: TF b1323 has unknown expression status; no mean expression or percentile data are available. Consequently, condition‑specific validation cannot be assessed, and all edges are evaluated solely on literature presence and CLR Z‑score strength. | Batch 4: The transcription factor b1323 shows no documented regulatory interactions with the majority of its predicted targets; only the b1323→b0390 edge is supported by literature. All statistical associations have CLR Z‑scores well below the strong‑data threshold (>4.0) and exhibit zero Pearson correlation, indicating that the inferred network is largely driven by weak or indirect signals. Consequently, most edges are classified as ProbableFalsePos and should be removed, while the single literature‑supported edge is retained as a ConditionSilent case, reflecting a context‑specific interaction not captured in the current dataset.

2025-12-11 04:56:16.613 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 04:56:16.614 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 8: Processing batch of 5 TFs (60 remaining)
2025-12-11 04:56:16.614 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b0069', 'b1608', 'b0564', 'b0162', 'b1328']
2025-12-11 04:56:16.614 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 04:56:16.615 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 04:56:16.618 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 04:56:16.620 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 50 pairs for speed
2025-12-11 04:56:16.620 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 04:56:16.621 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0069 -> b0066
2025-12-11 04:56:16.622 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:56:19,568 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:20.170 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:56:21,518 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:21.521 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:56:23,519 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:23.522 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:56:24,586 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:24.590 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0069 -> b0067
2025-12-11 04:56:24.592 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:56:25,988 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:26.409 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:56:28,168 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:28.171 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:56:30,222 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:30.225 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:56:31,553 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:31.556 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0069 -> b0068
2025-12-11 04:56:31.558 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:56:33,701 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:34.101 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:56:36,056 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:36.058 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:56:37,593 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:37.595 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:56:38,617 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:38.620 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0069 -> b0070
2025-12-11 04:56:38.622 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:56:42,609 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:42.988 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:56:44,657 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:44.661 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:56:46,724 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:46.726 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:56:48,129 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:48.132 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0069 -> b0069
2025-12-11 04:56:48.133 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:56:50,629 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:51.105 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 04:56:52,541 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:52.545 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 04:56:54,094 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:54.096 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 04:56:55,205 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 04:56:55.209 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 04:56:55.209 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 04:56:55.210 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 04:56:55.211 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 04:56:55.218 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0069
2025-12-11 04:56:58.884 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0069: 2 high, 156 moderate significance hits
2025-12-11 04:56:58.885 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1608
2025-12-11 04:57:02.517 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1608: 6 high, 148 moderate significance hits
2025-12-11 04:57:02.517 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0564
2025-12-11 04:57:06.224 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0564: 2 high, 143 moderate significance hits
2025-12-11 04:57:06.225 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0162
2025-12-11 04:57:09.871 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0162: 6 high, 154 moderate significance hits
2025-12-11 04:57:09.871 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1328
2025-12-11 04:57:13.533 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1328: 14 high, 172 moderate significance hits
2025-12-11 04:57:13.534 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 04:57:13.534 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 04:57:13.534 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b0069: 10 lit targets, 161 stat targets, 164 total
2025-12-11 04:57:48.781 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 164 edges for TF b0069
2025-12-11 04:57:48.786 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 164 edges in 4 batches (Max 50/batch)
2025-12-11 04:57:48.786 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 05:00:45,035 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:00:45.039 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:00:45.039 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:00:45.040 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 05:02:30,777 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:02:30.781 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 05:03:56,897 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:03:56.900 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (14 edges)
2025-12-11 05:04:33,557 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:04:33.561 | WARNING  | src.nodes.reviewer_agent:reviewer_agent_node:90 - LLM failed (17 validation errors for SubgraphReview
edge_decisions.66.explanation
  String should have at least 100 characters [type=string_too_short, input_value='The CLR (2.5458) is mode...robable false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.67.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.5442 with no curat...‑confidence category.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.70.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.1009 and absence o...robable false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.71.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.1069 with no curat... low‑confidence zone.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.74.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.2096 and absence o...dge is likely spurious.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.75.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.3467 with no liter...se‑positive category.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.77.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.1197 with no suppo...confidence prediction.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.78.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.2099 and absence o...false‑positive group.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.79.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.0510 with no curat...dge is likely spurious.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.80.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.1401 and lack of l...robable false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.82.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.1215 with no suppo...dge is likely spurious.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.83.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.5931 and absence o...se‑positive category.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.86.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.0643 with no suppo...robable false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.87.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.3364 and absence o...low‑confidence group.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.92.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.1984 with no liter...ikely a false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.94.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.0373 with no suppo...dge is likely spurious.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.95.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR 2.7774 is relatively...robable false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short), using rule-based fallback
2025-12-11 05:04:33.564 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b0069' using RULES method

Edges Reviewed: 164

Status Breakdown:
  - ConditionSilent: 159
  - NovelHypothesis: 2
  - ProbableFalsePos: 1
  - Validated: 2

TF-Level Notes:
Rule-based fallback used (LLM unavailable)

2025-12-11 05:04:33.565 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 05:04:33.566 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 9: Processing batch of 5 TFs (55 remaining)
2025-12-11 05:04:33.566 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b0034', 'b1512', 'b0315', 'b0506', 'b0487']
2025-12-11 05:04:33.566 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 05:04:33.567 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 05:04:33.567 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 05:04:33.569 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 45 pairs for speed
2025-12-11 05:04:33.569 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 05:04:33.569 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0034 -> b0036
2025-12-11 05:04:33.570 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:04:37,950 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:04:38.522 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:05:37,659 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:05:37.662 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:05:40,627 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:05:40.629 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:05:42,063 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:05:42.067 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0034 -> b0037
2025-12-11 05:05:42.068 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:05:44,621 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:05:45.053 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:05:47,181 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:05:47.184 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:05:49,132 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:05:49.135 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:05:50,667 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:05:50.671 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0034 -> b0038
2025-12-11 05:05:50.672 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:05:53,061 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:05:53.407 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:05:55,682 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:05:55.686 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:05:58,652 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:05:58.654 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:06:56,715 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:06:56.719 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0034 -> b0039
2025-12-11 05:06:56.720 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:06:59,168 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:06:59.559 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:07:02,244 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:07:02.248 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:07:04,290 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:07:04.292 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:08:06,347 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:08:06.350 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0034 -> b0040
2025-12-11 05:08:06.352 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:08:09,317 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:08:09.898 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:08:12,285 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:08:12.289 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:08:14,361 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:08:14.364 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:08:15,869 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:08:15.873 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 05:08:15.873 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 05:08:15.874 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 05:08:15.875 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 05:08:15.879 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0034
2025-12-11 05:08:19.485 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0034: 3 high, 144 moderate significance hits
2025-12-11 05:08:19.485 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1512
2025-12-11 05:08:23.190 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1512: 12 high, 152 moderate significance hits
2025-12-11 05:08:23.190 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0315
2025-12-11 05:08:26.782 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0315: 6 high, 156 moderate significance hits
2025-12-11 05:08:26.783 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0506
2025-12-11 05:08:30.419 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0506: 4 high, 170 moderate significance hits
2025-12-11 05:08:30.420 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0487
2025-12-11 05:08:34.064 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0487: 6 high, 175 moderate significance hits
2025-12-11 05:08:34.064 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 05:08:34.064 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 05:08:34.064 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b0034: 9 lit targets, 153 stat targets, 153 total
2025-12-11 05:09:05.260 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 153 edges for TF b0034
2025-12-11 05:09:05.264 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 153 edges in 4 batches (Max 50/batch)
2025-12-11 05:09:05.264 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 05:11:52,908 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:11:52.909 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:11:52.909 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:11:52.909 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 05:14:47,918 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:14:47.920 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 2 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:14:47.920 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:14:47.921 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 05:16:32,727 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:16:32.730 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (3 edges)
2025-12-11 05:17:02,217 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:02.221 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 1' to target b0313 using index 0
2025-12-11 05:17:02.221 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 2' to target b4287 using index 1
2025-12-11 05:17:02.221 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 3' to target b3166 using index 2
2025-12-11 05:17:02.221 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 4' to target b0564 using index 3
2025-12-11 05:17:02.221 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 5' to target b0038 using index 4
2025-12-11 05:17:02.221 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 6' to target b3792 using index 5
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 7' to target b3628 using index 6
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 8' to target b1448 using index 7
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 9' to target b3115 using index 8
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 10' to target b1700 using index 9
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 11' to target b1678 using index 10
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 12' to target b0405 using index 11
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 13' to target b4193 using index 12
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 14' to target b0063 using index 13
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 15' to target b2747 using index 14
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 16' to target b3196 using index 15
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 17' to target b3572 using index 16
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 18' to target b3560 using index 17
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 19' to target b1776 using index 18
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 20' to target b3069 using index 19
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 21' to target b0728 using index 20
2025-12-11 05:17:02.222 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 22' to target b3741 using index 21
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 23' to target b0036 using index 22
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 24' to target b0052 using index 23
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 25' to target b2764 using index 24
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 26' to target b2748 using index 25
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 27' to target b3617 using index 26
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 28' to target b2422 using index 27
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 29' to target b3703 using index 28
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 30' to target b0040 using index 29
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 31' to target b2954 using index 30
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 32' to target b0286 using index 31
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 33' to target b0039 using index 32
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 34' to target b0798 using index 33
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 35' to target b0919 using index 34
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 36' to target b0636 using index 35
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 37' to target b2235 using index 36
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 38' to target b4375 using index 37
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 39' to target b0044 using index 38
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 40' to target b3982 using index 39
2025-12-11 05:17:02.223 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 41' to target b3493 using index 40
2025-12-11 05:17:02.224 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 42' to target b2146 using index 41
2025-12-11 05:17:02.224 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 43' to target b3700 using index 42
2025-12-11 05:17:02.224 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 44' to target b2960 using index 43
2025-12-11 05:17:02.224 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 45' to target b0825 using index 44
2025-12-11 05:17:02.224 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 46' to target b1672 using index 45
2025-12-11 05:17:02.224 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 47' to target b3184 using index 46
2025-12-11 05:17:02.224 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 48' to target b3955 using index 47
2025-12-11 05:17:02.224 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 49' to target b0261 using index 48
2025-12-11 05:17:02.224 | INFO     | src.nodes.reviewer_agent:post_process_decisions:619 - Resolved 'Edge 50' to target b3067 using index 49
2025-12-11 05:17:02.224 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b0034' using LLM method

Edges Reviewed: 153

Status Breakdown:
  - ConditionSilent: 102
  - No literature support; data insufficient for strong inference: 3
  - NovelHypothesis: 3
  - Uncertain: 45

TF-Level Notes:
Batch 3: TF b0034 has unknown expression status; no expression quantification is available in the current dataset, limiting the ability to assess condition‑specific activity. | Batch 4: TF b0034 has no reported expression data (Is Expressed: Unknown, Mean Expression: N/A). All three outgoing edges lack literature support and exhibit only modest CLR scores (~2.2) with zero correlation, indicating weak statistical signals. Contextual checks also fail for each edge. Consequently, there is insufficient evidence to retain any of the proposed regulatory relationships for b0034 in the curated network.

2025-12-11 05:17:02.225 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 05:17:02.225 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 10: Processing batch of 5 TFs (50 remaining)
2025-12-11 05:17:02.225 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b0694', 'b0413', 'b1570', 'b1299', 'b1916']
2025-12-11 05:17:02.225 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 05:17:02.226 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 05:17:02.226 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 05:17:02.227 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 43 pairs for speed
2025-12-11 05:17:02.228 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 05:17:02.228 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0694 -> b0698
2025-12-11 05:17:02.229 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:17:05,083 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:05.588 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:17:07,605 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:07.610 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:17:09,526 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:09.527 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:17:12,569 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:12.572 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0694 -> b0697
2025-12-11 05:17:12.573 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:17:16,761 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:17.152 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:17:18,646 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:18.649 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:17:21,057 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:21.060 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:17:22,190 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:22.194 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0694 -> b0696
2025-12-11 05:17:22.196 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:17:24,643 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:25.064 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:17:27,479 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:27.482 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:17:29,540 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:29.543 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:17:31,092 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:31.096 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0694 -> b3714
2025-12-11 05:17:31.097 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:17:35,293 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:35.685 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:17:37,494 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:37.497 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:17:39,593 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:39.596 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:17:41,539 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:41.543 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0694 -> b3995
2025-12-11 05:17:41.544 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:17:44,099 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:44.618 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:17:47,073 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:17:47.076 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:18:42,779 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:18:42.782 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:18:44,925 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:18:44.929 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 05:18:44.930 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 05:18:44.930 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 05:18:44.932 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 05:18:44.935 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0694
2025-12-11 05:18:48.593 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0694: 2 high, 132 moderate significance hits
2025-12-11 05:18:48.594 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0413
2025-12-11 05:18:52.141 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0413: 4 high, 179 moderate significance hits
2025-12-11 05:18:52.141 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1570
2025-12-11 05:18:55.768 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1570: 5 high, 134 moderate significance hits
2025-12-11 05:18:55.768 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1299
2025-12-11 05:18:59.361 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1299: 9 high, 124 moderate significance hits
2025-12-11 05:18:59.361 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1916
2025-12-11 05:19:02.961 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1916: 5 high, 160 moderate significance hits
2025-12-11 05:19:02.961 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 05:19:02.962 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 05:19:02.962 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b0694: 9 lit targets, 140 stat targets, 140 total
2025-12-11 05:19:30.764 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 140 edges for TF b0694
2025-12-11 05:19:30.767 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 140 edges in 3 batches (Max 50/batch)
2025-12-11 05:19:30.767 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/3 (50 edges)
2025-12-11 05:22:08,603 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:22:08.606 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:22:08.606 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:22:08.607 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/3 (50 edges)
2025-12-11 05:24:34,526 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:24:34.530 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 2 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:24:34.530 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:24:34.531 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/3 (40 edges)
2025-12-11 05:26:24,198 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:26:24.204 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b0694' using LLM method

Edges Reviewed: 140

Status Breakdown:
  - ConditionSilent: 100
  - NovelHypothesis: 2
  - ProbableFalsePos: 37
  - Validated: 1

TF-Level Notes:
Batch 3: The transcription factor b0694 shows a single strong statistical signal (b0694→b0545) without prior literature, representing a novel hypothesis. Several edges (b0694→b3092, b0694→b0953, b0694→b3995, b0694→b0698, b0694→b4513) have solid literature support but lack statistical activation under the examined conditions, fitting a ConditionSilent pattern. The majority of predicted edges lack literature corroboration and exhibit only moderate CLR scores, leading to a ProbableFalsePos classification. No edge meets the combined strong literature and strong data criteria required for a Validated status.

2025-12-11 05:26:24.205 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 05:26:24.205 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 11: Processing batch of 5 TFs (45 remaining)
2025-12-11 05:26:24.205 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1434', 'b1303', 'b1356', 'b1735', 'b0346']
2025-12-11 05:26:24.206 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 05:26:24.206 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 05:26:24.207 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 05:26:24.209 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 38 pairs for speed
2025-12-11 05:26:24.209 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 05:26:24.209 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1434 -> b3607
2025-12-11 05:26:24.210 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:26:26,626 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:26:27.158 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:26:50,719 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:26:50.723 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:26:53,995 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:26:53.997 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:26:55,124 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:26:55.128 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1434 -> b1723
2025-12-11 05:26:55.129 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:26:58,603 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:26:58.994 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:27:00,755 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:00.758 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:27:03,212 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:03.214 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:27:05,567 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:05.570 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1434 -> b1922
2025-12-11 05:27:05.571 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:27:08,743 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:09.220 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:27:11,202 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:11.206 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:27:13,760 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:13.762 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:27:15,295 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:15.299 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1434 -> b1921
2025-12-11 05:27:15.301 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:27:19,699 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:20.088 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:27:22,261 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:22.265 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:27:24,308 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:24.311 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:27:25,743 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:25.746 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1434 -> b4547
2025-12-11 05:27:25.747 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:27:28,214 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:28.617 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:27:30,231 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:30.234 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:27:32,089 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:32.090 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:27:33,730 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:27:33.734 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 05:27:33.735 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 05:27:33.735 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 05:27:33.736 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 05:27:33.741 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1434
2025-12-11 05:27:37.253 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1434: 3 high, 152 moderate significance hits
2025-12-11 05:27:37.253 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1303
2025-12-11 05:27:40.856 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1303: 3 high, 171 moderate significance hits
2025-12-11 05:27:40.857 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1356
2025-12-11 05:27:44.489 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1356: 3 high, 133 moderate significance hits
2025-12-11 05:27:44.490 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1735
2025-12-11 05:27:48.071 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1735: 13 high, 201 moderate significance hits
2025-12-11 05:27:48.072 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0346
2025-12-11 05:27:51.696 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0346: 15 high, 143 moderate significance hits
2025-12-11 05:27:51.697 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 05:27:51.697 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 05:27:51.697 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1434: 8 lit targets, 159 stat targets, 160 total
2025-12-11 05:28:24.843 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 160 edges for TF b1434
2025-12-11 05:28:24.847 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 160 edges in 4 batches (Max 50/batch)
2025-12-11 05:28:24.847 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 05:30:59,662 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:30:59.666 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 05:33:16,379 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:33:16.383 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 2 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:33:16.383 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:33:16.384 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 05:35:57,250 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:35:57.254 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 3 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:35:57.255 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:35:57.256 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (10 edges)
2025-12-11 05:36:25,777 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:25.784 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1434' using LLM method

Edges Reviewed: 160

Status Breakdown:
  - ConditionSilent: 99
  - NovelHypothesis: 3
  - ProbableFalsePos: 58

TF-Level Notes:
Batch 1: TF b1434 has unknown expression status; no mean or percentile data are available, limiting context-specific interpretation of its regulatory network. | Batch 4: The transcription factor b1434 has no available expression data (unknown expression status, no mean or percentile values). Across all ten candidate targets, literature searches returned no evidence of regulatory relationships, and none of the computational CLR scores exceed the strong‑data threshold of 4.0. Correlation coefficients are uniformly zero, indicating no linear association. Given the systematic lack of literature support and only moderate statistical signals, the overall confidence in any of these edges is low, and they are best treated as probable false positives pending further experimental validation.

2025-12-11 05:36:25.785 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 05:36:25.785 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 12: Processing batch of 5 TFs (40 remaining)
2025-12-11 05:36:25.785 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b0911', 'b0294', 'b1914', 'b1508', 'b0840']
2025-12-11 05:36:25.785 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 05:36:25.786 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 05:36:25.787 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 05:36:25.788 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 35 pairs for speed
2025-12-11 05:36:25.789 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 05:36:25.789 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0911 -> b3261
2025-12-11 05:36:25.790 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:36:39,339 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:39.868 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:36:41,286 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:41.290 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:36:43,127 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:43.129 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:36:44,239 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:44.243 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0911 -> b1818
2025-12-11 05:36:44.245 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:36:46,298 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:46.721 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:36:49,064 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:49.069 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:36:51,113 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:51.115 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:36:52,342 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:52.346 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0911 -> b3164
2025-12-11 05:36:52.348 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:36:54,696 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:55.135 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:36:57,051 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:57.051 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:36:59,102 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:36:59.104 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:37:00,944 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:37:00.948 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0911 -> b0911
2025-12-11 05:37:00.949 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:37:05,965 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:37:05.968 | WARNING  | src.nodes.research_agent:research_agent_node:1252 - Error analyzing b0911 -> b0911: 'NoneType' object has no attribute 'strip'
2025-12-11 05:37:05.968 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0911 -> b3165
2025-12-11 05:37:05.978 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:37:09,050 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:37:09.448 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:37:10,866 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:37:10.869 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:37:12,358 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:37:12.360 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:37:13,438 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:37:13.443 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 05:37:13.444 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 05:37:13.445 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 05:37:13.445 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 05:37:13.448 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0911
2025-12-11 05:37:16.957 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0911: 18 high, 204 moderate significance hits
2025-12-11 05:37:16.957 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0294
2025-12-11 05:37:20.477 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0294: 17 high, 151 moderate significance hits
2025-12-11 05:37:20.478 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1914
2025-12-11 05:37:24.040 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1914: 4 high, 171 moderate significance hits
2025-12-11 05:37:24.040 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1508
2025-12-11 05:37:27.566 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1508: 4 high, 160 moderate significance hits
2025-12-11 05:37:27.566 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0840
2025-12-11 05:37:31.179 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0840: 7 high, 176 moderate significance hits
2025-12-11 05:37:31.179 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 05:37:31.180 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 05:37:31.180 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b0911: 7 lit targets, 208 stat targets, 209 total
2025-12-11 05:38:13.023 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 209 edges for TF b0911
2025-12-11 05:38:13.026 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 209 edges in 5 batches (Max 50/batch)
2025-12-11 05:38:13.026 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/5 (50 edges)
2025-12-11 05:40:12,744 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:40:12.748 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:40:12.748 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:40:12.749 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/5 (50 edges)
2025-12-11 05:42:14,203 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:42:14.207 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/5 (50 edges)
2025-12-11 05:44:23,534 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:44:23.538 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 3 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:44:23.539 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:44:23.540 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/5 (50 edges)
2025-12-11 05:46:39,108 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:46:39.110 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 4 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:46:39.111 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:46:39.111 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 5/5 (9 edges)
2025-12-11 05:47:33,934 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:33.939 | WARNING  | src.nodes.reviewer_agent:reviewer_agent_node:90 - LLM failed (23 validation errors for SubgraphReview
edge_decisions.62.explanation
  String should have at least 100 characters [type=string_too_short, input_value='The edge lacks both stro...therefore not retained.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.68.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Moderate CLR without any...; edge is not retained.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.69.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Statistical evidence is ...tudy; edge is excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.71.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Moderate CLR without any...; edge is not retained.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.72.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Statistical signal is mo...rted; edge is excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.73.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Moderate CLR without lit...dence; edge is omitted.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.74.explanation
  String should have at least 100 characters [type=string_too_short, input_value='The edge lacks both stro...re; it is not retained.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.76.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Moderate statistical sup...dence; edge is omitted.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.77.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Statistical evidence is ...; edge is not retained.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.78.explanation
  String should have at least 100 characters [type=string_too_short, input_value='The edge shows only mode...low, so it is excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.80.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Moderate CLR without any...dence; edge is omitted.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.81.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Statistical evidence is ...; edge is not retained.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.82.explanation
  String should have at least 100 characters [type=string_too_short, input_value='The edge lacks strong da...idence; it is excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.84.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Moderate CLR without any...dence; edge is omitted.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.85.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Statistical signal is mo...e edge is not retained.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.86.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Only a modest CLR and no...o the edge is excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.89.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Moderate CLR without lit...; edge is not retained.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.90.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Statistical evidence is ...rted; edge is excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.91.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Only moderate CLR and no...so the edge is omitted.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.93.explanation
  String should have at least 100 characters [type=string_too_short, input_value='The edge lacks strong da...rature; it is excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.95.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Moderate CLR without lit...dence; edge is omitted.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.97.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Statistical evidence is ...ture; edge is excluded.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.98.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Moderate CLR without any...dence; edge is omitted.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short), using rule-based fallback
2025-12-11 05:47:33.943 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b0911' using RULES method

Edges Reviewed: 209

Status Breakdown:
  - ConditionSilent: 189
  - NovelHypothesis: 18
  - ProbableFalsePos: 2

TF-Level Notes:
Rule-based fallback used (LLM unavailable)

2025-12-11 05:47:33.944 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 05:47:33.944 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 13: Processing batch of 5 TFs (35 remaining)
2025-12-11 05:47:33.944 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1574', 'b1450', 'b0796', 'b0535', 'b0330']
2025-12-11 05:47:33.945 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 05:47:33.945 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 05:47:33.946 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 05:47:33.948 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 29 pairs for speed
2025-12-11 05:47:33.948 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 05:47:33.948 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1574 -> b0095
2025-12-11 05:47:33.949 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:47:37,580 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:38.124 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:47:40,448 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:40.451 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:47:42,495 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:42.497 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:47:43,724 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:43.727 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1574 -> b1817
2025-12-11 05:47:43.728 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:47:45,233 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:45.637 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:47:47,717 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:47.721 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:47:49,051 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:49.053 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:47:50,205 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:50.208 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1574 -> b1854
2025-12-11 05:47:50.209 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:47:52,732 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:53.134 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:47:55,090 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:55.093 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:47:56,931 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:56.934 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:47:58,734 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:47:58.738 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1574 -> b3569
2025-12-11 05:47:58.740 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:48:01,132 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:48:01.604 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:48:03,233 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:48:03.235 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:48:05,127 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:48:05.128 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:48:06,149 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:48:06.152 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1574 -> b3005
2025-12-11 05:48:06.153 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:48:08,300 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:48:08.674 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:48:10,699 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:48:10.702 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:48:12,805 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:48:12.808 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:48:14,544 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:48:14.549 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 05:48:14.550 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 05:48:14.550 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 05:48:14.552 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 05:48:14.556 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1574
2025-12-11 05:48:18.101 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1574: 7 high, 187 moderate significance hits
2025-12-11 05:48:18.101 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1450
2025-12-11 05:48:21.618 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1450: 8 high, 176 moderate significance hits
2025-12-11 05:48:21.618 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0796
2025-12-11 05:48:25.210 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0796: 6 high, 148 moderate significance hits
2025-12-11 05:48:25.211 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0535
2025-12-11 05:48:28.795 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0535: 7 high, 179 moderate significance hits
2025-12-11 05:48:28.795 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0330
2025-12-11 05:48:32.413 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0330: 8 high, 167 moderate significance hits
2025-12-11 05:48:32.413 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 05:48:32.414 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 05:48:32.414 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1574: 6 lit targets, 192 stat targets, 192 total
2025-12-11 05:49:09.591 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 192 edges for TF b1574
2025-12-11 05:49:09.595 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 192 edges in 4 batches (Max 50/batch)
2025-12-11 05:49:09.595 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 05:51:16,088 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:51:16.092 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 05:53:05,369 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:53:05.373 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 2 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:53:05.373 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:53:05.374 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 05:55:27,405 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:55:27.410 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 3 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 05:55:27.410 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 05:55:27.411 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (42 edges)
2025-12-11 05:57:45,355 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:57:45.365 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1574' using LLM method

Edges Reviewed: 192

Status Breakdown:
  - ConditionSilent: 95
  - NovelHypothesis: 5
  - ProbableFalsePos: 50
  - Reviewed: 42

TF-Level Notes:
Batch 1: The transcription factor b1574 has unknown expression status, and none of its putative targets are supported by existing literature. Most inferred edges display CLR scores in the 2.0–3.9 range, which is below the strong‑data threshold, and all have zero Pearson correlation, suggesting weak or indirect statistical associations. Only one edge (b1574→b1387) reaches a CLR >4.0, providing strong computational evidence despite the lack of literature, and is therefore flagged as a novel hypothesis. Overall, the subgraph is dominated by low‑confidence predictions, and experimental validation should focus on the high‑CLR novel candidate while treating the remaining edges as likely false positives. | Batch 4: TF b1574 has unknown expression status; no expression data are available to assess condition‑specific activity. Consequently, all edges were evaluated solely on literature presence and CLR Z‑score strength. The majority lack literature support and exhibit only moderate CLR values, leading to a predominant classification as probable false positives. Two edges (b1574→b1828 and b1574→b1010) display strong CLR (>4) without prior literature, representing novel hypotheses worth experimental follow‑up. Two edges (b1574→b3569 and b1574→b0095) have strong literature but weak data, fitting the ConditionSilent category.

2025-12-11 05:57:45.366 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 05:57:45.367 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 14: Processing batch of 5 TFs (30 remaining)
2025-12-11 05:57:45.367 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1284', 'b0272', 'b0817', 'b0338', 'b1201']
2025-12-11 05:57:45.367 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 05:57:45.367 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 05:57:45.369 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 05:57:45.370 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 25 pairs for speed
2025-12-11 05:57:45.370 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 05:57:45.370 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1284 -> b4109
2025-12-11 05:57:45.371 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:57:51,992 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:57:52.525 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:57:55,577 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:57:55.580 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:57:58,444 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:57:58.447 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:58:00,084 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:00.088 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1284 -> b0573
2025-12-11 05:58:00.090 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:58:04,179 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:04.629 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:58:06,840 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:06.844 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:58:09,315 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:09.317 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:58:10,424 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:10.429 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1284 -> b0824
2025-12-11 05:58:10.432 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:58:13,599 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:13.989 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:58:15,850 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:15.853 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:58:17,903 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:17.906 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:58:18,826 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:18.830 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1284 -> b4189
2025-12-11 05:58:18.831 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:58:22,098 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:22.488 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:58:24,838 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:24.841 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:58:27,220 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:27.222 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:58:28,349 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:28.353 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1284 -> b0203
2025-12-11 05:58:28.355 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:58:31,109 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:31.481 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 05:58:32,952 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:32.956 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 05:58:34,898 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:34.900 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 05:58:36,537 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 05:58:36.541 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 05:58:36.541 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 05:58:36.542 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 05:58:36.544 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 05:58:36.548 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1284
2025-12-11 05:58:40.060 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1284: 5 high, 142 moderate significance hits
2025-12-11 05:58:40.060 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0272
2025-12-11 05:58:43.590 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0272: 13 high, 132 moderate significance hits
2025-12-11 05:58:43.591 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0817
2025-12-11 05:58:47.173 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0817: 6 high, 151 moderate significance hits
2025-12-11 05:58:47.174 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0338
2025-12-11 05:58:50.783 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0338: 5 high, 147 moderate significance hits
2025-12-11 05:58:50.783 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1201
2025-12-11 05:58:54.467 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1201: 3 high, 149 moderate significance hits
2025-12-11 05:58:54.468 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 05:58:54.468 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 05:58:54.468 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1284: 5 lit targets, 146 stat targets, 147 total
2025-12-11 05:59:23.006 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 147 edges for TF b1284
2025-12-11 05:59:23.009 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 147 edges in 3 batches (Max 50/batch)
2025-12-11 05:59:23.009 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/3 (50 edges)
2025-12-11 06:01:53,762 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:01:53.763 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/3 (50 edges)
2025-12-11 06:03:39,437 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:03:39.442 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/3 (47 edges)
2025-12-11 06:05:29,221 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:29.230 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1284' using LLM method

Edges Reviewed: 147

Status Breakdown:
  - NovelHypothesis: 5
  - ProbableFalsePos: 95
  - Reviewed: 47

TF-Level Notes:
Batch 1: TF b1284 has unknown expression status; no mean expression or percentile data are available. Consequently, all regulatory edges are evaluated solely on literature presence and CLR statistical strength, with none matching documented experimental conditions. | Batch 2: Across all 50 candidate edges for TF b1284, none are supported by strong literature (no curated interactions with high‑confidence evidence) and none achieve the CLR >4.0 threshold required for strong data. A handful of edges have weak literature mentions, but their statistical scores are zero, providing no quantitative backing. Consequently, every edge is classified as a ProbableFalsePos and should not be retained in the regulatory network. | Batch 3: The transcription factor b1284 lacks expression data and no literature supports any of its predicted targets. All CLR scores are below the strong‑data threshold (>4.0) and correlations are zero, indicating that the inferred network is likely driven by noise or indirect associations. Consequently, none of the candidate edges meet criteria for validation; they are best treated as probable false positives.

2025-12-11 06:05:29.231 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 06:05:29.231 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 15: Processing batch of 5 TFs (25 remaining)
2025-12-11 06:05:29.231 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1422', 'b0313', 'b1618', 'b0566', 'b1162']
2025-12-11 06:05:29.231 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 06:05:29.232 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 06:05:29.233 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 06:05:29.234 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 24 pairs for speed
2025-12-11 06:05:29.235 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 06:05:29.235 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1422 -> b0382
2025-12-11 06:05:29.236 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:05:32,071 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:32.753 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:05:34,540 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:34.543 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:05:37,048 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:37.050 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:05:38,062 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:38.066 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1422 -> b1493
2025-12-11 06:05:38.067 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:05:39,717 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:40.214 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:05:42,720 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:42.723 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:05:45,281 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:45.283 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:05:47,124 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:47.128 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1422 -> b4435
2025-12-11 06:05:47.130 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:05:49,583 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:50.010 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:05:52,242 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:52.246 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:05:54,199 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:54.200 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:05:55,760 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:55.764 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1422 -> b2000
2025-12-11 06:05:55.765 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:05:58,092 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:05:58.542 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:06:00,638 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:06:00.642 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:06:02,176 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:06:02.179 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:06:03,815 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:06:03.817 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1422 -> b2331
2025-12-11 06:06:03.818 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:06:06,249 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:06:06.740 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:06:08,324 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:06:08.328 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:06:11,191 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:06:11.193 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:06:12,622 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:06:12.627 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 06:06:12.627 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 06:06:12.628 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 06:06:12.629 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 06:06:12.633 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1422
2025-12-11 06:06:16.119 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1422: 9 high, 156 moderate significance hits
2025-12-11 06:06:16.119 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0313
2025-12-11 06:06:19.604 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0313: 3 high, 121 moderate significance hits
2025-12-11 06:06:19.605 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1618
2025-12-11 06:06:23.133 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1618: 0 high, 154 moderate significance hits
2025-12-11 06:06:23.133 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0566
2025-12-11 06:06:26.695 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0566: 2 high, 203 moderate significance hits
2025-12-11 06:06:26.695 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1162
2025-12-11 06:06:30.257 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1162: 6 high, 151 moderate significance hits
2025-12-11 06:06:30.258 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 06:06:30.258 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 06:06:30.258 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1422: 5 lit targets, 161 stat targets, 161 total
2025-12-11 06:07:03.446 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 161 edges for TF b1422
2025-12-11 06:07:03.448 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 161 edges in 4 batches (Max 50/batch)
2025-12-11 06:07:03.448 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 06:08:17,961 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:08:17.964 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 06:09:24,936 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:09:24.939 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 2 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 06:09:24.940 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 06:09:24.941 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 06:10:26,065 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:10:26.070 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (11 edges)
2025-12-11 06:10:47,673 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:10:47.679 | WARNING  | src.nodes.reviewer_agent:reviewer_agent_node:90 - LLM failed (2 validation errors for SubgraphReview
edge_decisions.138.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR\u202f=\u202f2.29 and... edge should be pruned.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.144.explanation
  String should have at least 100 characters [type=string_too_short, input_value='CLR\u202f=\u202f2.09 and...edge should be removed.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short), using rule-based fallback
2025-12-11 06:10:47.682 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1422' using RULES method

Edges Reviewed: 161

Status Breakdown:
  - ConditionSilent: 148
  - NovelHypothesis: 9
  - ProbableFalsePos: 4

TF-Level Notes:
Rule-based fallback used (LLM unavailable)

2025-12-11 06:10:47.683 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 06:10:47.683 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 16: Processing batch of 5 TFs (20 remaining)
2025-12-11 06:10:47.683 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b0603', 'b0169', 'b0345', 'b1620', 'b1530']
2025-12-11 06:10:47.683 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 06:10:47.683 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 06:10:47.684 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 06:10:47.685 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 16 pairs for speed
2025-12-11 06:10:47.685 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 06:10:47.685 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0603 -> b0601
2025-12-11 06:10:47.686 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:10:49,488 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:10:51.982 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:10:54,532 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:10:54.536 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:10:56,491 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:10:56.493 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:10:58,151 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:10:58.154 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0603 -> b0602
2025-12-11 06:10:58.155 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:11:00,164 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:00.577 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:11:02,725 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:02.728 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:11:04,670 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:04.673 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:11:06,516 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:06.520 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0603 -> b0603
2025-12-11 06:11:06.521 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:11:10,200 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:10.664 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:11:12,517 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:12.521 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:11:15,116 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:15.119 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:11:16,755 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:16.759 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0603 -> b4173
2025-12-11 06:11:16.760 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:11:19,621 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:20.012 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:11:22,081 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:22.084 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:11:24,227 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:24.230 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:11:25,631 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:25.634 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0169 -> b0169
2025-12-11 06:11:25.636 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:11:28,631 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:31.507 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:11:34,161 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:34.166 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:11:36,111 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:36.114 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:11:37,745 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:11:37.749 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 06:11:37.749 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 06:11:37.750 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 06:11:37.751 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 06:11:37.756 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0603
2025-12-11 06:11:41.273 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0603: 1 high, 147 moderate significance hits
2025-12-11 06:11:41.274 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0169
2025-12-11 06:11:44.732 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0169: 23 high, 203 moderate significance hits
2025-12-11 06:11:44.733 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0345
2025-12-11 06:11:48.313 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0345: 0 high, 131 moderate significance hits
2025-12-11 06:11:48.313 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1620
2025-12-11 06:11:51.847 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1620: 0 high, 148 moderate significance hits
2025-12-11 06:11:51.847 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1530
2025-12-11 06:11:55.447 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1530: 1 high, 157 moderate significance hits
2025-12-11 06:11:55.447 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 06:11:55.447 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 06:11:55.448 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b0603: 4 lit targets, 148 stat targets, 149 total
2025-12-11 06:12:25.794 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 149 edges for TF b0603
2025-12-11 06:12:25.797 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 149 edges in 3 batches (Max 50/batch)
2025-12-11 06:12:25.797 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/3 (50 edges)
2025-12-11 06:13:53,325 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:13:53.326 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 06:13:53.326 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 06:13:53.326 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/3 (50 edges)
2025-12-11 06:15:48,015 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:15:48.019 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 2 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 06:15:48.019 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 06:15:48.020 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/3 (49 edges)
2025-12-11 06:17:55,637 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:17:55.648 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b0603' using LLM method

Edges Reviewed: 149

Status Breakdown:
  - ConditionSilent: 100
  - NovelHypothesis: 1
  - ProbableFalsePos: 47
  - Validated: 1

TF-Level Notes:
Batch 3: TF b0603 has no expression data available, and none of the surveyed target genes have documented regulatory interactions under the examined conditions. The majority of edges rely solely on statistical inference (CLR scores ranging 2.0‑3.9) without supporting literature, leading to a systematic classification as probable false positives. Only two edges (b0603→b0602 and b0603→b4173) have literature evidence; the former is strongly supported experimentally but lacks strong statistical backing, while the latter has weak literature support and very weak statistical evidence. Overall, the subgraph lacks robust multi‑evidence support and should be treated with caution.

2025-12-11 06:17:55.649 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 06:17:55.649 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 17: Processing batch of 5 TFs (15 remaining)
2025-12-11 06:17:55.649 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1827', 'b0730', 'b1564', 'b0504', 'b1649']
2025-12-11 06:17:55.650 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 06:17:55.650 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 06:17:55.651 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 06:17:55.653 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 15 pairs for speed
2025-12-11 06:17:55.653 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 06:17:55.653 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1827 -> b1850
2025-12-11 06:17:55.654 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:17:57,863 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:17:58.326 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:18:00,727 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:00.730 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:18:03,291 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:03.294 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:18:04,311 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:04.316 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1827 -> b1851
2025-12-11 06:18:04.318 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:18:07,288 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:07.688 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:18:09,329 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:09.332 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:18:10,799 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:10.802 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:18:12,198 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:12.202 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1827 -> b0994
2025-12-11 06:18:12.203 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:18:14,756 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:15.148 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:18:18,239 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:18.243 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:18:20,287 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:20.290 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:18:22,847 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:22.851 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0730 -> b0730
2025-12-11 06:18:22.852 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:18:25,312 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:25.697 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:18:28,752 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:28.755 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:18:31,265 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:31.267 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:18:32,371 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:32.375 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0730 -> b0731
2025-12-11 06:18:32.377 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:18:34,419 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:34.896 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:18:36,878 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:36.882 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:18:39,268 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:39.270 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:18:40,461 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:18:40.465 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 06:18:40.465 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 06:18:40.466 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 06:18:40.467 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 06:18:40.471 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1827
2025-12-11 06:18:44.019 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1827: 3 high, 161 moderate significance hits
2025-12-11 06:18:44.020 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0730
2025-12-11 06:18:47.525 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0730: 4 high, 152 moderate significance hits
2025-12-11 06:18:47.526 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1564
2025-12-11 06:18:51.075 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1564: 2 high, 112 moderate significance hits
2025-12-11 06:18:51.076 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0504
2025-12-11 06:18:54.698 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0504: 4 high, 167 moderate significance hits
2025-12-11 06:18:54.698 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1649
2025-12-11 06:18:58.322 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1649: 4 high, 154 moderate significance hits
2025-12-11 06:18:58.322 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 06:18:58.322 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 06:18:58.322 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1827: 3 lit targets, 162 stat targets, 162 total
2025-12-11 06:19:29.921 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 162 edges for TF b1827
2025-12-11 06:19:29.924 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 162 edges in 4 batches (Max 50/batch)
2025-12-11 06:19:29.925 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 06:21:40,177 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:21:40.181 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 06:21:40.181 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 06:21:40.182 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 06:22:41,207 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:22:41.210 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 06:23:42,340 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:23:42.344 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (12 edges)
2025-12-11 06:24:20,536 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:20.541 | WARNING  | src.nodes.reviewer_agent:reviewer_agent_node:90 - LLM failed (1 validation error for SubgraphReview
edge_decisions.145.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature; CLR = 2.3...ikely a false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short), using rule-based fallback
2025-12-11 06:24:20.545 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1827' using RULES method

Edges Reviewed: 162

Status Breakdown:
  - ConditionSilent: 157
  - NovelHypothesis: 2
  - ProbableFalsePos: 1
  - Validated: 2

TF-Level Notes:
Rule-based fallback used (LLM unavailable)

2025-12-11 06:24:20.546 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 06:24:20.546 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 18: Processing batch of 5 TFs (10 remaining)
2025-12-11 06:24:20.546 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1853', 'b0305', 'b1111', 'b1384', 'b1438']
2025-12-11 06:24:20.546 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 06:24:20.547 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 06:24:20.548 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 06:24:20.550 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 12 pairs for speed
2025-12-11 06:24:20.550 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 06:24:20.550 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1853 -> b1853
2025-12-11 06:24:20.551 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:24:24,940 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:25.452 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:24:27,383 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:27.388 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:24:29,446 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:29.448 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:24:31,358 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:31.361 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1853 -> b3281
2025-12-11 06:24:31.362 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:24:33,335 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:34.062 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:24:35,908 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:35.911 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:24:37,434 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:37.436 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:24:38,968 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:38.971 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1853 -> b2537
2025-12-11 06:24:38.972 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:24:41,370 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:41.762 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:24:43,372 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:43.374 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:24:45,522 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:45.524 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:24:46,854 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:46.859 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0305 -> b0301
2025-12-11 06:24:46.860 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:24:49,309 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:49.676 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:24:51,974 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:51.977 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:24:54,276 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:54.277 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:24:55,903 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:55.907 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0305 -> b0304
2025-12-11 06:24:55.908 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:24:58,021 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:24:58.423 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:25:00,471 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:25:00.474 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:25:02,933 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:25:02.935 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:25:04,568 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:25:04.573 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 06:25:04.573 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 06:25:04.573 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 06:25:04.574 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 06:25:04.579 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1853
2025-12-11 06:25:08.107 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1853: 10 high, 147 moderate significance hits
2025-12-11 06:25:08.107 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0305
2025-12-11 06:25:11.669 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0305: 3 high, 148 moderate significance hits
2025-12-11 06:25:11.670 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1111
2025-12-11 06:25:15.241 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1111: 0 high, 153 moderate significance hits
2025-12-11 06:25:15.242 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1384
2025-12-11 06:25:18.796 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1384: 3 high, 167 moderate significance hits
2025-12-11 06:25:18.796 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1438
2025-12-11 06:25:22.408 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1438: 7 high, 149 moderate significance hits
2025-12-11 06:25:22.409 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 06:25:22.409 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 06:25:22.409 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1853: 3 lit targets, 149 stat targets, 150 total
2025-12-11 06:25:51.634 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 150 edges for TF b1853
2025-12-11 06:25:51.637 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 150 edges in 3 batches (Max 50/batch)
2025-12-11 06:25:51.637 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/3 (50 edges)
2025-12-11 06:28:07,766 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:28:07.770 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 06:28:07.771 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 06:28:07.772 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/3 (50 edges)
2025-12-11 06:30:14,642 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:30:14.646 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/3 (50 edges)
2025-12-11 06:32:04,723 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:04.728 | WARNING  | src.nodes.reviewer_agent:reviewer_agent_node:90 - LLM failed (9 validation errors for SubgraphReview
edge_decisions.64.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No experimental support ... and probably indirect.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.79.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absence of literature an...bably a false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.86.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No curated evidence; CLR...a true regulatory link.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.88.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No literature; CLR 2.16 ...ikely a false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.89.explanation
  String should have at least 100 characters [type=string_too_short, input_value='Absence of literature an...e is probably spurious.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.91.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No experimental evidence...ikely a false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.93.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No curated evidence; CLR...a true regulatory link.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.95.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No experimental record; ...e is probably spurious.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short
edge_decisions.99.explanation
  String should have at least 100 characters [type=string_too_short, input_value='No experimental evidence...ikely a false positive.', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/string_too_short), using rule-based fallback
2025-12-11 06:32:04.732 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1853' using RULES method

Edges Reviewed: 150

Status Breakdown:
  - ConditionSilent: 138
  - NovelHypothesis: 10
  - ProbableFalsePos: 2

TF-Level Notes:
Rule-based fallback used (LLM unavailable)

2025-12-11 06:32:04.733 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 06:32:04.733 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 19: Processing batch of 5 TFs (5 remaining)
2025-12-11 06:32:04.733 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b1716', 'b0447', 'b1014', 'b1696', 'b1790']
2025-12-11 06:32:04.733 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 06:32:04.734 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 06:32:04.734 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 06:32:04.743 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 10 pairs for speed
2025-12-11 06:32:04.743 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 06:32:04.743 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1716 -> b1716
2025-12-11 06:32:04.744 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:32:08,820 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:09.407 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:32:11,788 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:11.791 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:32:14,248 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:14.250 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:32:15,577 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:15.581 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1716 -> b1717
2025-12-11 06:32:15.583 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:32:17,728 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:18.104 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:32:20,901 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:20.905 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:32:23,056 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:23.058 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:32:25,100 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:25.105 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0447 -> b3110
2025-12-11 06:32:25.107 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:32:27,000 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:27.381 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:32:29,401 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:29.405 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:32:31,047 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:31.049 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:32:34,626 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:34.630 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0447 -> b3109
2025-12-11 06:32:34.632 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:32:36,877 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:37.269 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:32:39,845 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:39.848 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:32:41,794 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:41.795 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:32:43,430 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:43.434 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1014 -> b1014
2025-12-11 06:32:43.435 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:32:48,308 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:48.709 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:32:51,623 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:51.627 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:32:53,873 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:53.873 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:32:55,862 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:32:55.865 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 06:32:55.865 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 06:32:55.866 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 06:32:55.867 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 06:32:55.870 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1716
2025-12-11 06:32:59.386 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1716: 10 high, 170 moderate significance hits
2025-12-11 06:32:59.386 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0447
2025-12-11 06:33:02.908 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0447: 1 high, 119 moderate significance hits
2025-12-11 06:33:02.909 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1014
2025-12-11 06:33:06.487 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1014: 5 high, 169 moderate significance hits
2025-12-11 06:33:06.487 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1696
2025-12-11 06:33:10.044 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1696: 2 high, 186 moderate significance hits
2025-12-11 06:33:10.044 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1790
2025-12-11 06:33:13.639 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1790: 2 high, 161 moderate significance hits
2025-12-11 06:33:13.640 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 06:33:13.640 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 06:33:13.640 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b1716: 2 lit targets, 170 stat targets, 171 total
2025-12-11 06:33:46.861 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 171 edges for TF b1716
2025-12-11 06:33:46.863 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 171 edges in 4 batches (Max 50/batch)
2025-12-11 06:33:46.863 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 06:35:05,669 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:35:05.674 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 06:35:05.675 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 06:35:05.676 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 06:36:07,927 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:36:07.930 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 06:37:10,187 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:37:10.190 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (21 edges)
2025-12-11 06:37:44,151 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:37:44.154 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b1716' using LLM method

Edges Reviewed: 171

Status Breakdown:
  - ConditionSilent: 48
  - NovelHypothesis: 9
  - ProbableFalsePos: 113
  - Validated: 1

TF-Level Notes:
Batch 2: The transcription factor b1716 shows no documented expression data and the majority of its predicted targets lack any literature support. Most edges have only weak statistical evidence (CLR < 4), leading to a high proportion of probable false positives. A few edges (b3294, b2606, b1718, b1088) exhibit strong CLR scores (>4) despite absent literature, representing novel hypotheses that merit experimental validation. The self‑regulatory edge is supported by literature but not by the current dataset, falling into a condition‑silent category. | Batch 3: b1716 shows no documented expression data, and none of the predicted targets have condition‑matched literature. Only the self‑edge to b1717 is strongly supported; one novel high‑CLR edge (b3175) may merit experimental follow‑up. | Batch 4: The transcription factor b1716 has no reported expression data (Is Expressed: Unknown, Mean Expression: N/A). The lack of expression information limits the ability to assess condition‑specific regulation, contributing to the overall uncertainty of its inferred targets.

2025-12-11 06:37:44.155 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 06:37:44.155 | INFO     | src.nodes.batch_manager:batch_manager_node:62 - Iteration 20: Processing batch of 5 TFs (0 remaining)
2025-12-11 06:37:44.155 | DEBUG    | src.nodes.batch_manager:batch_manager_node:66 - Current batch TFs: ['b0357', 'b1540', 'b1659', 'b0208', 'b1358']
2025-12-11 06:37:44.156 | INFO     | src.nodes.batch_manager:check_queue_status:96 - Continuing with 5 TFs to process
2025-12-11 06:37:44.156 | INFO     | src.nodes.research_agent:research_agent_node:1185 - === RESEARCH AGENT NODE: Literature-informed context filtering ===
2025-12-11 06:37:44.157 | INFO     | src.nodes.research_agent:research_agent_node:1208 - Context filtering: 466 samples selected from 466 total
2025-12-11 06:37:44.158 | WARNING  | src.nodes.research_agent:research_agent_node:1225 - Limiting literature analysis to 5 of 8 pairs for speed
2025-12-11 06:37:44.158 | INFO     | src.nodes.research_agent:research_agent_node:1228 - Processing 5 gene pairs for literature analysis
2025-12-11 06:37:44.158 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0357 -> b0356
2025-12-11 06:37:44.159 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:37:46,846 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:37:47.409 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:37:49,514 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:37:49.518 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:37:51,765 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:37:51.767 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:37:53,496 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:37:53.497 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b0357 -> b0355
2025-12-11 06:37:53.497 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:37:55,803 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:37:56.216 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:37:58,418 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:37:58.420 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:38:01,695 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:01.697 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:38:03,027 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:03.030 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1540 -> b1580
2025-12-11 06:38:03.032 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:38:05,279 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:05.665 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:38:06,985 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:06.988 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:38:09,271 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:09.274 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:38:10,607 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:10.614 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1540 -> b1581
2025-12-11 06:38:10.616 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:38:13,062 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:13.468 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:38:16,237 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:16.240 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:38:18,386 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:18.388 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:38:20,128 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:20.131 | DEBUG    | src.nodes.research_agent:research_agent_node:1246 - Analyzing b1659 -> b1660
2025-12-11 06:38:20.132 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:38:23,404 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:23.804 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.3, MaxT: None)
2025-12-11 06:38:26,887 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:26.890 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.5, MaxT: None)
2025-12-11 06:38:28,728 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:28.730 | INFO     | src.llm.alcf_client:chat:109 - LLM Request -> openai/gpt-oss-20b (Temp: 0.1, MaxT: None)
2025-12-11 06:38:30,350 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:38:30.352 | INFO     | src.nodes.research_agent:research_agent_node:1257 - Literature analysis completed: 5 gene pairs processed
2025-12-11 06:38:30.353 | INFO     | src.nodes.research_agent:research_agent_node:1292 - Research Agent completed: context filtering and literature analysis done
2025-12-11 06:38:30.353 | INFO     | src.nodes.analysis_agent:analysis_agent_node:69 - === ANALYSIS AGENT NODE: Computing CLR & Mutual Information ===
2025-12-11 06:38:30.354 | INFO     | src.nodes.analysis_agent:analysis_agent_node:112 - Analyzing 5 TFs across 466 samples
2025-12-11 06:38:30.357 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0357
2025-12-11 06:38:33.894 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0357: 2 high, 151 moderate significance hits
2025-12-11 06:38:33.894 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1540
2025-12-11 06:38:37.380 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1540: 4 high, 143 moderate significance hits
2025-12-11 06:38:37.380 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1659
2025-12-11 06:38:40.885 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1659: 6 high, 199 moderate significance hits
2025-12-11 06:38:40.885 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b0208
2025-12-11 06:38:44.426 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b0208: 5 high, 142 moderate significance hits
2025-12-11 06:38:44.426 | INFO     | src.nodes.analysis_agent:analysis_agent_node:125 - Processing TF: b1358
2025-12-11 06:38:47.965 | INFO     | src.nodes.analysis_agent:_analyze_single_tf:272 - TF b1358: 11 high, 223 moderate significance hits
2025-12-11 06:38:47.965 | INFO     | src.nodes.analysis_agent:analysis_agent_node:154 - Analysis complete for 5 TFs
2025-12-11 06:38:47.966 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:55 - === REVIEWER AGENT NODE: Literature-Informed Reconciliation ===
2025-12-11 06:38:47.966 | INFO     | src.nodes.reviewer_agent:prepare_subgraph_data:130 - TF b0357: 2 lit targets, 151 stat targets, 151 total
2025-12-11 06:39:16.839 | INFO     | src.nodes.reviewer_agent:reviewer_agent_node:78 - Reviewing 151 edges for TF b0357
2025-12-11 06:39:16.842 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:370 - Processing 151 edges in 4 batches (Max 50/batch)
2025-12-11 06:39:16.842 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 1/4 (50 edges)
2025-12-11 06:40:56,648 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:40:56.652 | ERROR    | src.nodes.reviewer_agent:invoke_llm_reviewer:420 - Batch 1 failed: Invalid json output: 
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-12-11 06:40:56.652 | WARNING  | src.nodes.reviewer_agent:invoke_llm_reviewer:424 - Triggering Rule-Based Fallback for failed batch
2025-12-11 06:40:56.653 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 2/4 (50 edges)
2025-12-11 06:42:50,476 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:42:50.479 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 3/4 (50 edges)
2025-12-11 06:44:30,320 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:44:30.324 | INFO     | src.nodes.reviewer_agent:invoke_llm_reviewer:373 - Processing Batch 4/4 (1 edges)
2025-12-11 06:44:40,351 - httpx - INFO - HTTP Request: POST https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-11 06:44:40.356 | INFO     | src.nodes.reviewer_agent:post_process_decisions:674 - Reviewer Agent: Completed review of TF 'b0357' using LLM method

Edges Reviewed: 151

Status Breakdown:
  - ConditionSilent: 50
  - NovelHypothesis: 49
  - ProbableFalsePos: 1
  - Reviewed: 50
  - Validated: 1

TF-Level Notes:
Batch 2: TF b0357 has no reported expression data, making it difficult to assess condition‑specific activity. Across 50 candidate targets, only the self‑regulatory edge b0357→b0356 is supported by strong literature and a very high CLR score, qualifying it as a validated interaction. All other edges lack any literature evidence and exhibit CLR Z‑scores well below the >4.0 strong‑data threshold, with zero expression correlation and no condition compatibility. Consequently, they are best classified as probable false positives and should be removed from the curated network pending new experimental validation. | Batch 3: The transcription factor b0357 shows no documented regulatory interactions in the current literature except for a strong self‑regulatory edge to b0355. Statistical analysis across 50 candidate targets yields CLR scores ranging from ~2.0 to 3.8, none reaching the >4.0 strong‑data threshold required for independent validation. Consequently, most edges lack sufficient evidence and are classified as novel hypotheses pending experimental verification. The only edge with both strong literature and data (b0357→b0355) is retained as validated. | Batch 4: Expression status of TF b0357 is unknown; no quantitative expression data are available, limiting the ability to assess condition‑specific activity.

2025-12-11 06:44:40.358 | INFO     | src.nodes.batch_manager:batch_manager_node:33 - === BATCH MANAGER NODE: Selecting next TF batch ===
2025-12-11 06:44:40.358 | INFO     | src.nodes.batch_manager:batch_manager_node:50 - TF queue is empty, workflow complete
2025-12-11 06:44:40.358 | INFO     | src.nodes.batch_manager:check_queue_status:89 - Workflow status: completed
2025-12-11 06:44:40.358 | INFO     | src.workflow:run_reconciliation:172 - ============================================================
2025-12-11 06:44:40.358 | INFO     | src.workflow:run_reconciliation:173 - RECONCILIATION COMPLETE
2025-12-11 06:44:40.358 | INFO     | src.workflow:run_reconciliation:174 - ============================================================
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:201 - Total edges analyzed: 3718
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:202 - Status breakdown:
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:204 -   - ConditionSilent: 2354
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:204 -   - No literature support; data insufficient for strong inference: 3
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:204 -   - NovelHypothesis: 180
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:204 -   - ProbableFalsePos: 845
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:204 -   - Reviewed: 203
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:204 -   - Uncertain: 92
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:204 -   - Validated: 41
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:205 - Novel hypotheses: 180
2025-12-11 06:44:40.360 | INFO     | src.workflow:_log_summary:206 - Probable false positives: 845
2025-12-11 06:44:40.361 | INFO     | src.workflow:_log_summary:210 - Top novel discoveries (by z-score):
2025-12-11 06:44:40.361 | INFO     | src.workflow:_log_summary:217 -   1. b1921 → b1083 (z=8.13)
2025-12-11 06:44:40.361 | INFO     | src.workflow:_log_summary:217 -   2. b1221 → b1222 (z=7.53)
2025-12-11 06:44:40.361 | INFO     | src.workflow:_log_summary:217 -   3. b1921 → b1946 (z=7.36)
2025-12-11 06:44:40.361 | INFO     | src.workflow:_log_summary:217 -   4. b1853 → b2125 (z=7.10)
2025-12-11 06:44:40.361 | INFO     | src.workflow:_log_summary:217 -   5. b1921 → b1925 (z=7.04)
2025-12-11 06:44:40,367 - evaluation.metrics.base_metric - INFO - [MetricASabotage] Computing scores...
2025-12-11 06:44:40,368 - evaluation.metrics.base_metric - INFO - [MetricASabotage] Generating plots...
2025-12-11 06:44:40,635 - evaluation.metrics.base_metric - INFO - [MetricASabotage] Completed. Results saved to evaluation/outputs_scaled_100/MetricASabotage_results.json
2025-12-11 06:44:40,636 - __main__ - INFO - DONE. Report at evaluation/outputs_scaled_100/report_MetricASabotage.md
